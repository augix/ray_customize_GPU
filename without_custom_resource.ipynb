{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 16:09:31,157\tINFO worker.py:1654 -- Connecting to existing Ray cluster at address: 10.11.140.31:6379...\n",
      "2025-03-18 16:09:31,171\tINFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerator_type:G 2.0\n",
      "memory 585787361076.0\n",
      "object_store_memory 255337440460.0\n",
      "CPU 128.0\n",
      "GPU 4.0\n",
      "node:10.11.140.64 1.0\n",
      "node:__internal_head__ 1.0\n",
      "node:10.11.140.31 1.0\n",
      "finding 4 GPUs with free memory greater than 1 GB\n",
      "\u001b[36m(CustomGPU pid=7296)\u001b[0m selecting 10.11.140.31_GPU0\n",
      "Found eligible GPU: 10.11.140.31_GPU0, Free memory: 23.37 GB\n",
      "Found eligible GPU: 10.11.140.31_GPU1, Free memory: 23.42 GB\n",
      "Found eligible GPU: 10.11.140.64_GPU0, Free memory: 7.60 GB\n",
      "\u001b[36m(CustomGPU pid=1958707, ip=10.11.140.64)\u001b[0m selecting 10.11.140.64_GPU1\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Found eligible GPU: 10.11.140.64_GPU1, Free memory: 23.43 GB\n",
      "Eligible GPUs: ['10.11.140.31_GPU0', '10.11.140.31_GPU1', '10.11.140.64_GPU0', '10.11.140.64_GPU1']\n",
      "\u001b[36m(worker pid=7303)\u001b[0m start task at 16:09:40\n",
      "\u001b[36m(worker pid=7303)\u001b[0m end task at 16:09:45\n",
      "\u001b[36m(worker pid=1958810, ip=10.11.140.64)\u001b[0m selecting 10.11.140.64_GPU0\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(worker pid=1958810, ip=10.11.140.64)\u001b[0m start task at 16:09:41\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "[torch.Size([1000, 1000]), torch.Size([1000, 1000]), torch.Size([1000, 1000]), torch.Size([1000, 1000])]\n",
      "\u001b[36m(worker pid=1958809, ip=10.11.140.64)\u001b[0m end task at 16:09:46\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ray_func import *\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def my_task():\n",
    "    current_time = time.localtime()\n",
    "    print(f'start task at {current_time.tm_hour:02d}:{current_time.tm_min:02d}:{current_time.tm_sec:02d}')\n",
    "    time.sleep(5)\n",
    "    a = torch.randn(1000, 1000)\n",
    "    b = torch.randn(1000, 1000)\n",
    "    c = torch.matmul(a, b)\n",
    "    result = c.shape\n",
    "    current_time = time.localtime()\n",
    "    print(f'end task at {current_time.tm_hour:02d}:{current_time.tm_min:02d}:{current_time.tm_sec:02d}')\n",
    "    return result\n",
    "\n",
    "@ray.remote\n",
    "class worker:\n",
    "    def __init__(self, gpu_name):\n",
    "        select_gpu(gpu_name)\n",
    "\n",
    "    def task(self):\n",
    "        return my_task()\n",
    "\n",
    "def main():\n",
    "    # sort GPUs by free memory\n",
    "    # sorted_gpu_names = find_top_k_gpu(k=0)\n",
    "\n",
    "    # Run 4 workers on top 4 GPUs simultaneously\n",
    "    n_workers = 4\n",
    "    free_memory_threshold = 1 # GB\n",
    "    gpu_names = get_gpu_names()\n",
    "    eligible_gpu = find_eligible_gpu(gpu_names, n_gpu=n_workers, free_memory_threshold=free_memory_threshold)\n",
    "    print(f\"Eligible GPUs: {eligible_gpu}\")\n",
    "    if len(eligible_gpu) == n_workers:\n",
    "        node_names = [gpu.split('_GPU')[0] for gpu in eligible_gpu]\n",
    "        workers = [worker.options(resources={f\"node:{node_name}\": 0.01}).remote(gpu) for gpu, node_name in zip(eligible_gpu, node_names)]\n",
    "        results = ray.get([worker.task.remote() for worker in workers])\n",
    "        print(results)\n",
    "    # shutdown ray\n",
    "    ray.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ray_address = 'auto'\n",
    "    ray.init(address=ray_address, ignore_reinit_error=True)\n",
    "    res = ray.cluster_resources()\n",
    "    for k, v in res.items():\n",
    "        print(k, v)\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
